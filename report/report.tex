\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[pdftex]{graphicx}

    
\title{\textbf{Report on Big Data project: \\(short subtitle)}}

\author{
	Name Surname - Mat. 004815\\
	Name Surname - Mat. 162342}
	
\date{\today}

\begin{document}
\maketitle
\newpage

\tableofcontents

\newpage

\section{Teachers' notes}

The goal of the project is to assess the students' skills in writing jobs of low/medium complexity and to correctly reason about the jobs' performances. The projects must be agreed with the teachers (do not start without explicit consent) and require to:

\begin{itemize}
\item find a complex-enough dataset: at least 1GB, possibly consisting of more tables;
\item load the dataset on HDFS/Hive;
\item implement an analytical job in both MapReduce and Spark (minimum complexity of two shuffle operations);
\item carry out an evaluation of performances and optimize the job accordingly;
\item display results on Tableau (or similar visual tools);
\item writing a short report to describe the project.
\end{itemize}

To deliver the project, each group must {\bf send by email to both teachers the link to their repository}. The repository must:
\begin{itemize}
\item be created from the individual assignment available on the Github classroom;
\item contain a {\sf report} folder with the PDF of the final report (based on this template). The report can be written in either Italian/English and Latex/Word at your discretion. Be concise and go straight to the point: an excessively verbose report is a waste of time for you and for the teachers;
\item contain a {\sf README.md} file with the instruction to run the jobs. Indeed, the teachers must be able to clone the repository and run the jobs from their accounts on the cluster. This means that the dataset must be accessible on HDFS/Hive and the code must compile and run correctly. Please make the jobs repeatable (i.e., the job checks and possibly deletes old data to avoid errors when re-running the code).
\end{itemize}

This guide is based on the ``MapReduce+Spark'' kind of project. However, we remind that a different kind of project may be agreed upon.
\\

The evaluation will be based on the following.
\begin{itemize}
\item Compliance of the jobs with the agreed upon specifications.
\item Compliance of the report with this guide.
\item Job correctness.
\item Correct reasoning about optimizations.
\end{itemize}

Appreciated aspects.
\begin{itemize}
\item Code cleanliness and comments.
\item Further considerations in terms of job scalability and extensibility.
\end{itemize}



\section{Introduction}
\subsection{Dataset description}

Please provide:
\begin{itemize}
\item A brief description of the dataset.
\item The link to the website publishing the dataset (e.g., \url{https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page}).
\item Direct links to the downloaded files, especially if more than one files are available in the previous link (e.g., \url{https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2017-01.csv}).
\end{itemize}

\subsubsection{File description}

For each file, briefly indicate the available data and the fields used for the analyses; examples are welcome.


\section{Data preparation}

Please provide:
\begin{itemize}
\item The paths to each file on HDFS and/or the corresponding location in Hive (database and table).
\item A subsection with details on the pre-processing of the data (only necessary if the data is dirty and/or it contains a significant amount of useless information).
\end{itemize}


\section{Query}

One subsection for each query.

\subsection{Query \#1: short description}

Provide a brief, general description of the query. Then, one subsection for each implementation.

\subsubsection{MapReduce/Spark implementation}

Please provide:
\begin{itemize}
\item Input and output files/tables.
\item Execution time and amount of resources.
\item Direct links to the application's history on YARN (e.g., \url{http://isi-vclust0.csr.unibo.it:18088/history/application_15...}).
\item Description of the implementation. A schematic and concise discussion is preferable to a verbose narrative. Focus on how the data is manipulated in the job (e.g., what do keys and values represent across the different stages, what operations are carried out). 
\item Performance considerations with respect to the evaluated optimizations, e.g.:
\begin{itemize}
\item amount of allocated resources and tasks;
\item enforced partitioning;
\item data caching;
\item combiner usage;
\item broadcast variables usage;
\item any other kind of optimization.
\end{itemize}
\item Visualization of the output and discussion (i.e., whether there is any relevant insight obtained).
\end{itemize}

\section{Miscellaneous}

If necessary, feel free to add sections to discuss any other relevant aspect.

\end{document}
